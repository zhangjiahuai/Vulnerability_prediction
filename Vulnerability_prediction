
import re
import numpy as np
from sklearn.decomposition import PCA
import gensim
from gensim.models import Word2Vec
import pandas as pd
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import nltk
from keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Dropout,Dense,Input,Flatten,BatchNormalization
from tensorflow.keras.layers import Conv1D,MaxPooling1D,Embedding,concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing import sequence

from tensorflow.python.keras.layers.recurrent import LSTM,GRU

train = pd.read_csv('bert_data/all.csv',header=None)
# train[:10]
x_train = train[0].values
print(x_train.shape)
x_train = list(x_train)
# x_train[:10]


token = Tokenizer(num_words=30000) 


token.fit_on_texts(x_train)


x_train_seq = token.texts_to_sequences(x_train)
x_train = sequence.pad_sequences(x_train_seq,maxlen=1000,padding='post')
y = train[6].values
y = list(y)


sequence_input = Input(shape = (1000,)) 
embedding_layer = Embedding(30000,128,input_length=1000)
embedded_sequences = embedding_layer(sequence_input)

cnn1 = Conv1D(filters = 32,kernel_size=3,activation='relu')(embedded_sequences)
cnn1 = MaxPooling1D(pool_size=5)(cnn1)

cnn1 = Conv1D(filters = 32,kernel_size=3,activation='relu')(cnn1)
cnn1 = MaxPooling1D(pool_size=5)(cnn1)

cnn1 = Conv1D(filters = 32,kernel_size=3,activation='relu')(cnn1)
cnn1 = MaxPooling1D(pool_size=37)(cnn1)


lstm1 = LSTM(10,activation='relu')(cnn1)
lstm1 = Dense(20,activation = 'relu')(lstm1)
lstm1 = Dense(10,activation = 'tanh')(lstm1)
lstm1 = Dense(1024,activation = 'relu')(lstm1)

lstm1 = BatchNormalization()(lstm1)
lstm1 = Dropout(0.5)(lstm1)
out = Dense(1,activation = 'sigmoid')(lstm1)

model = Model(sequence_input,out)
model.summary()

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x_train, y, test_size=0.2, random_state=42)


model.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics=['accuracy'])


model.fit(np.array(X_train),np.array(y_train)
         ,batch_size=32
         ,verbose=True
         ,epochs=9  
         ,validation_data=(np.array(X_test),np.array(y_test)))

y_pred = model.predict(X_test)
for i in range(len(y_pred)):
    if y_pred[i] > 0.5:
        y_pred[i] = 1
    else:
        y_pred[i] = 0


from sklearn.metrics import precision_score
precison = precision_score(y_test, y_pred,average='weighted')

from sklearn.metrics import f1_score
f1 = f1_score(y_test,y_pred,average='weighted')

from sklearn.metrics import recall_score
recall = recall_score(y_test,y_pred,average='weighted')
